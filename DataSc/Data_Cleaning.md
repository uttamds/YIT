
# ğŸ“˜  Short Notes (Data Science Basics)

---

## ğŸŸ¢ Missing Values

Missing values are data entries that are not recorded (NaN/NULL).
They can affect model accuracy and must be handled before training.

---

## ğŸŸ¢ Methods to Handle Missing Numerical Data

Common methods include:

* **Mean imputation** â€“ replaces missing values with average
* **Median imputation** â€“ useful when data has outliers

---

## ğŸŸ¢ Categorical Data in Machine Learning

Machine learning models work only with numerical values.
Text or categories must be converted into numbers using encoding.

---

## ğŸŸ¢ Feature Scaling

Feature scaling brings different features to a common scale.
It prevents features with large values from dominating the model.

---

## ğŸŸ¢ Test Size in Trainâ€“Test Split

`test_size=0.2` means:

* 20% data is used for testing
* 80% data is used for training

---

## ğŸŸ¡ Mean vs Mode Imputation

* **Mean** is used for numerical data
* **Mode** is used for categorical data
  Choosing the correct method preserves data consistency.

---

## ğŸŸ¡ Label Encoding vs One-Hot Encoding

* **Label Encoding** assigns numbers to categories (Yes=1, No=0)
* **One-Hot Encoding** creates separate columns for each category
  One-Hot Encoding avoids false order in categorical data.

---

## ğŸŸ¡ Effect of Not Applying Feature Scaling

Without scaling:

* Features with larger values dominate
* Model performance becomes biased
  This is common with features like Salary vs Age.

---

## ğŸŸ¡ Role of `random_state`

`random_state` ensures reproducibility of results.
Using the same value gives the same trainâ€“test split every time.

---

## ğŸŸ¡ Detecting Missing Values in Pandas

Pandas provides built-in functions to detect missing data:

* `isnull()` identifies missing values
* `sum()` counts them per column

---

## ğŸ“Š What is Machine Learning?

* Machine learns patterns from *data*
* No hard-coded rules

Example idea:

* Give marks â†’ Predict pass/fail

---

## ğŸ“¦ Basic Python Libraries for AI

| Library        | Purpose          |
| -------------- | ---------------- |
| numpy        | Numbers          |
| pandas       | Tables (data)    |
| matplotlib   | Graphs           |
| scikit-learn | Machine Learning |

---

## ğŸ”¢ Step 1: Numbers with NumPy

python
import numpy as np

marks = np.array([35, 60, 75])
print(marks)


ğŸ‘‰ NumPy helps AI work with numbers fast.

---

## ğŸ“‹ Step 2: Data with Pandas

python
import pandas as pd

data = {
    "Marks": [35, 60, 75],
    "Result": ["Fail", "Pass", "Pass"]
}

df = pd.DataFrame(data)
print(df)


ğŸ‘‰ AI *learns from tables (data)*.

---

## ğŸ“ˆ Step 3: Visualize Data

python
import matplotlib.pyplot as plt

plt.plot(df["Marks"])
plt.show()


ğŸ‘‰ Graphs help humans *see patterns*.

---

## ğŸ¤– Step 4: First Machine Learning Idea

*Problem:*
ğŸ‘‰ Predict result based on marks

| Marks | Result |
| ----- | ------ |
| 35    | Fail   |
| 60    | Pass   |
| 75    | Pass   |

---

## ğŸ§ª Step 5: Train a Very Simple Model

python
from sklearn.linear_model import LinearRegression

X = [[35], [60], [75]]   # input
y = [0, 1, 1]            # output (0=Fail, 1=Pass)

model = LinearRegression()
model.fit(X, y)

print(model.predict([[50]]))


ğŸ‘‰ Output closer to 1 means *Pass*

---

## ğŸ§  What Just Happened?

* We *gave data*
* Model *learned pattern*
* Model *predicted new value*

That is *AI learning*

---

## ğŸ” Basic AI Workflow (Must Remember)

1. Collect Data
2. Clean Data
3. Train Model
4. Test Model
5. Predict

---

## ğŸ§¾ AI vs Normal Program

| Normal Program         | AI Program              |
| ---------------------- | ----------------------- |
| Rules written by human | Rules learned from data |
| Same output always     | Improves with more data |

---

## ğŸ¯ Key Takeaways (Exam / Interview Ready)

* AI mimics human intelligence
* Python is best for AI beginners
* Machine Learning = learning from data
* Model = program that learns
* Prediction is final goal




# ğŸ“Š Data Science Lesson Plan (Foundations)

## ğŸ¯ Learning Outcomes

By the end of this session, students will be able to:

* Handle missing data
* Encode categorical variables
* Apply feature scaling
* Perform trainâ€“test split

---

## ğŸ§© Sample Dataset (Used Throughout)

```python
import pandas as pd

data = {
    "Age": [22, 25, None, 28, 35],
    "Salary": [30000, 40000, 35000, None, 50000],
    "City": ["Bangalore", "Delhi", "Bangalore", "Mumbai", None],
    "Purchased": ["Yes", "No", "Yes", "No", "Yes"]
}

df = pd.DataFrame(data)
df
```

---

## 1ï¸âƒ£ Missing Values Handling

### ğŸ”¹ Identify Missing Values

```python
df.isnull()
```

```python
df.isnull().sum()
```

### ğŸ”¹ Handling Techniques

#### (a) Mean Imputation (Numerical)

```python
df["Age"].fillna(df["Age"].mean(), inplace=True)
df["Salary"].fillna(df["Salary"].mean(), inplace=True)
```

#### (b) Mode Imputation (Categorical)

```python
df["City"].fillna(df["City"].mode()[0], inplace=True)
```

âœ… **Students learn:**

* Real-world datasets always contain missing values
* Numerical â†’ mean/median
* Categorical â†’ mode

---

## 2ï¸âƒ£ Encoding (Categorical â†’ Numerical)

### ğŸ”¹ Label Encoding

```python
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df["Purchased"] = le.fit_transform(df["Purchased"])
```

### ğŸ”¹ One-Hot Encoding

```python
df_encoded = pd.get_dummies(df, columns=["City"])
df_encoded
```

âœ… **Students learn:**

* ML models work only with numbers
* Label Encoding for binary values
* One-Hot Encoding for multi-category features

---

## 3ï¸âƒ£ Feature Scaling

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
df_encoded[["Age", "Salary"]] = scaler.fit_transform(
    df_encoded[["Age", "Salary"]]
)
df_encoded
```

âœ… **Students learn:**

* Features with large values dominate models
* Scaling brings features to a common range
* StandardScaler centers data around zero

---

## 4ï¸âƒ£ Train / Test Split

```python
from sklearn.model_selection import train_test_split

X = df_encoded.drop("Purchased", axis=1)
y = df_encoded["Purchased"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(X_train.shape)
print(X_test.shape)
```

âœ… **Students learn:**

* Why models must be tested on unseen data
* Typical split: 80% train / 20% test
* Role of `random_state`

---

## ğŸ§  Learning Flow Summary

```
Raw Data
   â†“
Missing Values
   â†“
Encoding
   â†“
Scaling
   â†“
Train / Test Split
```

---

## ğŸ“ Quick Student Activities

1. Replace missing salary using **median**
2. Convert `City` using One-Hot Encoding
3. Try `test_size=0.3`
4. Print `X_test` only

